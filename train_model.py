# Importing essential libraries
import numpy as np
import pandas as pd
# Loading the dataset
df = pd.read_csv('heart.csv')

dataset = pd.get_dummies(df, columns=['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal'])

from sklearn.preprocessing import StandardScaler
standScaler = StandardScaler()
columns_to_scale = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']

# Fit the scaler on the columns to scale
standScaler.fit(dataset[columns_to_scale])

# Transform the dataset using the fitted scaler
dataset[columns_to_scale] = standScaler.transform(dataset[columns_to_scale])



# Splitting the dataset into dependent and independent features
X = dataset.drop('target', axis=1)
y = dataset['target']

# Importing essential libraries
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import cross_val_score


# Finding the best accuracy for knn algorithm using cross_val_score 
knn_scores = []
for i in range(1, 21):
  knn_classifier = KNeighborsClassifier(n_neighbors=i)
  cvs_scores = cross_val_score(knn_classifier, X, y, cv=10)
  knn_scores.append(round(cvs_scores.mean(),3))


# Training the knn classifier model with k value as 12
knn_classifier = KNeighborsClassifier(n_neighbors=12)
cvs_scores = cross_val_score(knn_classifier, X, y, cv=10)
print("KNeighbours Classifier Accuracy with K=12 is: {}%".format(round(cvs_scores.mean(), 4)*100))


# Importing essential libraries
from sklearn.tree import DecisionTreeClassifier

# Finding the best accuracy for decision tree algorithm using cross_val_score 
decision_scores = []
for i in range(1, 11):
  decision_classifier = DecisionTreeClassifier(max_depth=i)
  cvs_scores = cross_val_score(decision_classifier, X, y, cv=10)
  decision_scores.append(round(cvs_scores.mean(),3))


# Training the decision tree classifier model with max_depth value as 3
decision_classifier = DecisionTreeClassifier(max_depth=3)
cvs_scores = cross_val_score(decision_classifier, X, y, cv=10)
print("Decision Tree Classifier Accuracy with max_depth=3 is: {}%".format(round(cvs_scores.mean(), 4)*100))

# Importing essential libraries
from sklearn.ensemble import RandomForestClassifier

# Finding the best accuracy for random forest algorithm using cross_val_score 
forest_scores = []
for i in range(10, 101, 10):
  forest_classifier = RandomForestClassifier(n_estimators=i)
  cvs_scores = cross_val_score(forest_classifier, X, y, cv=5)
  forest_scores.append(round(cvs_scores.mean(),3))

# Training the random forest classifier model with n value as 90
forest_classifier = RandomForestClassifier(n_estimators=90)

# Train the model using fit()
forest_classifier.fit(X, y)  # Ensure the model is trained

# Use cross_val_score to calculate accuracy after fitting
cvs_scores = cross_val_score(forest_classifier, X, y, cv=5)
print("Random Forest Classifier Accuracy with n_estimators=90 is: {}%".format(round(cvs_scores.mean(), 4) * 100))


import joblib  # For saving the model

# Saving the trained Random Forest model as a .pkl file
joblib.dump(forest_classifier, 'best_random_forest_model.pkl')
print("Random Forest model saved as 'best_random_forest_model.pkl'")


# Saving the trained StandardScaler as a .pkl file
joblib.dump(standScaler, 'scaler.pkl')
print("StandardScaler saved as 'scaler.pkl'")